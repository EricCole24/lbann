"""Utility functions for LC systems.

These are a convenience for developers and users at LLNL.

"""

import os, os.path
import datetime
import lbann.proto as lp
from lbann.utils import lbann_dir
from lbann.lc.systems import *
from lbann.lc.paths import *
import lbann.lc.slurm

# ==============================================
# Run experiments
# ==============================================

def run(model, data_reader, optimizer,
        work_dir = None,
        lbann_exe = lbann_exe(),
        lbann_args = '',
        job_name = 'lbann',
        nodes = 1,
        procs_per_node = procs_per_node(),
        partition = partition(),
        account = account(),
        time_limit = time_limit()):
    """Run LBANN experiment.

    This will either submit a batch job to the scheduler (if on a
    login node) or run LBANN with the current node allocation (if on a
    compute node). Behavior may vary across systems and schedulers.

    If a work directory is not provided, a timestamped directory is
    created (by default in `lbann/experiments`). The location of
    autogenerated work directories can be set with the environment
    variable `LBANN_EXPERIMENT_DIR`.

    Args:
        model (lbann.proto.Model or lbann_pb2.Model): Neural network
            model.
        data_reader (lbann_pb2.DataReader): Data reader.
        optimizer (lbann.proto.Model or lbann_pb2.Optimizer): Default
            optimizer for model.
        work_dir (str, optional): Work directory.
        lbann_exe (str, optional): LBANN executable.
        lbann_args (str, optional): Command-line arguments to LBANN
            executable.
        job_name (str, optional): Batch job name.
        nodes (int, optional): Number of compute nodes.
        procs_per_node (int, optional): Number of processes per compute
            node.
        partition (str, optional): Scheduler partition.
        account (str, optional): Scheduler account.
        time_limit (int, optional): Job time limit, in minutes.

    """

    # Construct work directory if needed
    if not work_dir:
        experiment_dir = os.path.join(lbann_dir(), 'experiments')
        if 'LBANN_EXPERIMENT_DIR' in os.environ:
            experiment_dir = os.environ['LBANN_EXPERIMENT_DIR']
        timestamp = datetime.datetime.now().strftime('%Y%m%d_%H%M%S')
        work_dir = os.path.join(experiment_dir,
                                '{}_{}'.format(timestamp, job_name))
        i = 1
        while os.path.lexists(work_dir):
            i += 1
            work_dir = os.path.join(experiment_dir,
                                    '{}_{}_{}'.format(timestamp, job_name, i))
    work_dir = os.path.abspath(work_dir)
    os.makedirs(work_dir, exist_ok=True)

    # Create experiment prototext file
    prototext_file = os.path.join(work_dir, 'experiment.prototext')
    lp.save_prototext(prototext_file,
                      model = model,
                      data_reader = data_reader,
                      optimizer = optimizer)

    # Run experiment
    if scheduler() == 'slurm':
        slurm.run(prototext_file = prototext_file,
                  job_name = job_name,
                  work_dir = work_dir,
                  lbann_exe = lbann_exe,
                  lbann_args = lbann_args,
                  nodes = nodes,
                  procs_per_node = procs_per_node,
                  partition = partition,
                  account = account,
                  time_limit = time_limit)
    else:
        raise RuntimeError('unsupported job scheduler ({})'
                           .format(scheduler()))
